{"cells":[{"cell_type":"markdown","source":["# Developing machine learning Regression model with Spark MLlib\n\nIn this lab you will learn how to develop a machine learning regression model using Spark MLlib in Azure Databricks environment. During the course of the lab you will walk through cardinal phases of a machine learning workflow from data gathering and cleaning through feature engineering and modeling to model inferencing.\n\n## Lab scenario\nYou will develop a machine learning  model to forecast number of crimes per each district of city of Chicago per each crime type per day. The dataset used during the lab contains historical information about crime situation of city of Chicago plus historical weather data and social economic data. You will use Azure Databricks unified analytics platform and Spark MLlib library and other option such as SKLearn. You will make use of Azure ML Services to assist in model management, version and metrics tracking during development"],"metadata":{}},{"cell_type":"code","source":["# import the Workspace class and check the azureml SDK version\n# exist_ok checks if workspace exists or not.\n\nfrom azureml.core import Workspace\nfrom azureml.core.authentication import InteractiveLoginAuthentication\n# subscription_id = \"726e384c-7d96-4ef7-b79f-bca70e05082e\" #you should be owner or contributor\nsubscription_id = \"be1b220b-fcad-4ce7-b323-6732ecc06c14\" #you should be owner or contributor\n\n# resource_group = \"edsPrdComWu2Rg0\" #you should be owner or contributor\nresource_group = \"pocdlkdevwu2rgtraning\" #you should be owner or contributor\n\n# workspace_name = \"aml01ws\" #your workspace name\nworkspace_name = \"commamlws01\" #your workspace name\n\nworkspace_region = \"westus2\" #your region\nws = Workspace.create(name = workspace_name,\n                      subscription_id = subscription_id,\n                      auth = InteractiveLoginAuthentication(force=True, tenant_id=\"be413eec-6262-4083-97c8-8c2a817c2fe1\"),\n                      resource_group = resource_group, \n                      location = workspace_region,\n                      \n                      exist_ok=True)\n\n\n "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ModuleNotFoundError</span>                       Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3279902021527038&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-red-fg\"># exist_ok checks if workspace exists or not.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> azureml<span class=\"ansi-blue-fg\">.</span>core <span class=\"ansi-green-fg\">import</span> Workspace\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-green-fg\">from</span> azureml<span class=\"ansi-blue-fg\">.</span>core<span class=\"ansi-blue-fg\">.</span>authentication <span class=\"ansi-green-fg\">import</span> InteractiveLoginAuthentication\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> <span class=\"ansi-red-fg\"># subscription_id = &#34;726e384c-7d96-4ef7-b79f-bca70e05082e&#34; #you should be owner or contributor</span>\n\n<span class=\"ansi-red-fg\">ModuleNotFoundError</span>: No module named &#39;azureml&#39;</div>"]}}],"execution_count":2},{"cell_type":"code","source":["#Create or retrieve your experiment. Experiment is a unit to group together experiment runs that share same nature and you're interested to compare runs together. \n\nfrom azureml.core.run import Run\nfrom azureml.core.experiment import Experiment\nimport shutil\nmyexperiment = Experiment(ws, \"AML_Crime_Prediction\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["## Loading and Feature Engineering"],"metadata":{}},{"cell_type":"markdown","source":["## Approach 1: Using Spark MLlib \n\n### What is MLlib?\n\nMLlib is a package, built on and included in Spark, that provides interfaces for\n- gathering and cleaning data,\n- feature engineering and feature selection,\n- training and tuning large scale supervised and unsupervised machine learning models, \n- and using those models in production.\n\n### MLlib Concepts\n\n![MLlib](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/MLlib.png)"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["#### Split data into training and test sets\n\nAt this point we will split our dataset into separate training and test sets."],"metadata":{}},{"cell_type":"code","source":["# loading data from the stored table\ncrime_df = spark.sql(\"select * from crime_dataset\").na.drop()\n# Split the dataset randomly into 85% for training and 15% for testing.\ntrain, test = crime_df.randomSplit([0.85, 0.15], 0)\ntrain.cache()\ntest.cache()\nprint(\"We have {} training examples and {} test examples.\".format(train.count(), test.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">We have 2015788 training examples and 356185 test examples.\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["#### Visualize our data\n\nNow that we have preprocessed our features and prepared a training dataset, we can use visualizations to get more insights about the data.\n\nCalling `display()` on a DataFrame in Databricks and clicking the plot icon below the table will let you draw and pivot various plots.  See the [Visualizations section of the Databricks Guide](https://docs.databricks.com/user-guide/visualizations/index.html) for more ideas."],"metadata":{}},{"cell_type":"code","source":["display(train)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["You can also use other visualization libraries."],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Get a sample of data\nsample = train.sample(False, 0.05, 42).toPandas()\n\nax = sample.plot.scatter(x='TMAX', y='crime_count')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["#### Save training and testing data\n\nAt this point, we are going to save the datasets using `Parquet` format"],"metadata":{}},{"cell_type":"markdown","source":["d ### Train a Machine Learning Pipeline\n\nNow that we have understood our data and prepared it as a DataFrame with pre-processed data, we are ready to train an ML classifier. In this lab we will focus on a single algorithm - Gradient-boosted tree classifier - however in most cases you should go through a more thorough model selection process to find an algorithm that best fits you scenario and training data. We will also demonstrate how to automate hyperparameter tuning using Spark ML validators.\n\nTo achieve it, we will put together a simple Spark ML Pipeline.\n\nMost Spark ML algorithms, including GBT, expect the training data to be provided as a *numeric* column to represent the label and a column of type *Vector* to represent the features. \n\nThe features in our datasets are a mix of *numeric* and *string* values. *String* columns represent categorical features. Most *numeric* columns are continous features. Before we can configure hyper parameter tuning and Random Forest stages of our pipeline we will need to add a few data transformation steps.\n\nOur complete pipeline has the following stages:\n\n* `StringIndexer`: Convert string columns to categorical features\n* `VectorAssembler`: Assemble the feature columns into a feature vector.\n* `VectorIndexer`: Identify columns which should be treated as categorical. This is done heuristically, identifying any column with a small number of distinct values as being categorical.  For us, this will include columns like `occupation` or `homeowner` .\n* `Classifier`: This stage will train the classification algorithm.\n* `CrossValidator`: The machine learning algorithms have several [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_optimization), and tuning them to our data can improve performance of the model.  We will do this tuning using Spark's [Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_&#40;statistics&#41;) framework, which automatically tests a grid of hyperparameters and chooses the best.\n\n![Image of Pipeline](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/pipeline.png)"],"metadata":{}},{"cell_type":"markdown","source":["First, we define the feature processing stages of the Pipeline:\n* Convert string columns to categorical features. \n* Assemble feature columns into a feature vector. \n* Identify categorical features, and index them.\n![Image of feature processing](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/features.png)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\nfrom pyspark.sql.types import *\nfrom pyspark.ml import Pipeline\ndef build_pipeline(features_to_remove):\n# Create a list of string indexers - one for each string column\n  stringCols = [field.name for field in train.schema if field.dataType == StringType()]\n  stringIndexers = [StringIndexer().setInputCol(name).setOutputCol(name+\"_idx\") for name in stringCols]\n\n  # Get a list of all numeric columns\n  numericCols = [field.name for field in train.schema if field.dataType != StringType()]\n\n  # Remove a label column and other unwanted features\n  for feature in features_to_remove:\n    numericCols.remove(feature)\n\n\n  #We create two pipelines, one with different sets of columns to compare results\n  #Pipeline 1, all original columns are included\n\n\n  # Create a list of all feature columns\n  featureCols = numericCols + [name + \"_idx\" for name in stringCols]\n\n  # This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\n  vectorAssembler = VectorAssembler(inputCols=featureCols, outputCol=\"rawFeatures\")\n\n  # This identifies categorical features and indexes them.\n  vectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=30)\n\n  # Create a pipeline\n  stages = stringIndexers + [vectorAssembler, vectorIndexer]\n  pipeline = Pipeline(stages=stages)\n  return pipeline\n\n# Check the Pipeline operation\n# display(pipeline.fit(train).transform(train))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Second, we define the model training stage of the Pipeline. `GBTClassifier` takes feature vectors and labels as input and learns to predict labels of new examples.\n![RF image](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/train.png)"],"metadata":{}},{"cell_type":"markdown","source":["Third, we wrap the model training stage within a `CrossValidator` stage.  `CrossValidator` knows how to call the classifier algorithm with different hyperparameter settings.  It will train multiple models and choose the best one, based on minimizing some metric.  In this lab, our metric is *AUC*.\n\n![Crossvalidate](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tune.png)"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Finally, we can tie our feature processing and model training stages together into a single `Pipeline`.\n\n![Image of Pipeline](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/pipeline.png)"],"metadata":{}},{"cell_type":"markdown","source":["#### Train the Pipeline!\n\nNow that we have set up our workflow, we can train the Pipeline in a single call.  Calling `fit()` will run feature processing, model tuning, and training in a single call.  We get back a fitted Pipeline with the best model found.\n\n***Note***: This next cell can take up to **10 minutes**.  This is because it is training *a lot* of trees:\n* For each random sample of data in Cross Validation,\n  * For each setting of the hyperparameters,\n    * `CrossValidator` is training a separate GBT ensemble which contains many Decision Trees.\n    \nSince our training set is unbalanced we will apply a technique called *under sampling*. We will use all instances of a minority class but select a random sample from the majority class."],"metadata":{}},{"cell_type":"code","source":["#Training with GLR model\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nfrom pyspark.ml.regression import GeneralizedLinearRegression\nimport os\nmodel_name = \"crime_prediction_GLR.mml\"\nmodel_dbfs = os.path.join(\"/dbfs\", model_name)\nrun_history_name = 'spark-ml-notebook'\n\nmyexperiment = Experiment(ws, \"AML_Crime_Prediction_Sumanth\")\nroot_run = myexperiment.start_logging()\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator(\n    labelCol=\"crime_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n\nregressor = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",featuresCol=\"features\", labelCol=\"crime_count\")\n\nparamGrid = ParamGridBuilder()\\\n  .addGrid(regressor.regParam, [0.2, 0.3])\\\n  .addGrid(regressor.maxIter, [15, 30])\\\n  .build()\ncv = CrossValidator(estimator=regressor, evaluator=evaluator,estimatorParamMaps=paramGrid, numFolds=3)\n\nwith root_run.child_run(\"full columns\") as run:\n  run.log(\"featureset\", \"full\")\n  # dt = DecisionTreeRegressor(featuresCol=\"features\")\n\n\n\n  pipeline = build_pipeline(['crime_count', 'year'])\n\n  stages = pipeline.getStages()\n  stages = stages + [cv]\n  pipeline.setStages(stages)\n  print(pipeline.getStages())\n  pipelineModel = pipeline.fit(train)\n  predictions = pipelineModel.transform(test).cache()\n  print(\"Model  weather features: {} on  test set: {}\".format(evaluator.getMetricName(), evaluator.evaluate(predictions, {})))\n  run.log(evaluator.getMetricName(), evaluator.evaluate(predictions, {}))\n  #Save model to local dbfs\n  pipelineModel.write().overwrite().save(model_name)\n\n  # upload the serialized model into run history record\n  mdl, ext = model_name.split(\".\")\n  model_zip = mdl + \".zip\"\n  shutil.make_archive(mdl, 'zip', model_dbfs)\n  run.upload_file(\"outputs/\" + model_name, model_zip)        \n\n  # now delete the serialized model from local folder since it is already uploaded to run history \n  shutil.rmtree(model_dbfs)\n  os.remove(model_zip)\nwith root_run.child_run(\"removed weather columns\") as run:\n  run.log(\"featureset\", \"minus weather\")\n  regressor = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",featuresCol=\"features\", labelCol=\"crime_count\")\n  # dt = DecisionTreeRegressor(featuresCol=\"features\")\n\n\n  cv = CrossValidator(estimator=regressor, evaluator=evaluator,estimatorParamMaps=paramGrid, numFolds=3)\n  pipeline = build_pipeline(['crime_count', 'year','PRCP','SNOW','SNWD','TMAX','TMIN','TOBS','WT01','WT03','WT04','WT05','WT06','WT11'])\n  stages = pipeline.getStages()\n  stages = stages + [cv]\n  pipeline.setStages(stages)\n  pipelineModel = pipeline.fit(train)\n  predictions = pipelineModel.transform(test).cache()\n  print(\"Model without weather features: {} on  test set: {}\".format(evaluator.getMetricName(), evaluator.evaluate(predictions, {})))\n  run.log(evaluator.getMetricName(), evaluator.evaluate(predictions, {}))\n\n  pipelineModel.write().overwrite().save(model_name)\n\n  # upload the serialized model into run history record\n  mdl, ext = model_name.split(\".\")\n  model_zip = mdl + \".zip\"\n  shutil.make_archive(mdl, 'zip', model_dbfs)\n  run.upload_file(\"outputs/\" + model_name, model_zip)        \n\n  # now delete the serialized model from local folder since it is already uploaded to run history \n  shutil.rmtree(model_dbfs)\n  os.remove(model_zip)\n    \nroot_run_id = root_run.id\nprint (\"run id:\", root_run.id)\n\n#Load all run metrics from run history into a dictionary object.\nchild_runs = {}\n\nfor r in root_run.get_children():\n    child_runs[r.id] = r\n    \nmetrics = root_run.get_metrics(recursive=True)\nbest_run_id = min(metrics, key = lambda k: metrics[k][evaluator.getMetricName()])\nbest_run = child_runs[best_run_id]\nprint('Best run is:', best_run_id)\nprint('Metrics {0}: {1} by model {2}'.format(evaluator.getMetricName(), metrics[best_run_id][evaluator.getMetricName()],metrics[best_run_id][\"featureset\"]))\nroot_run.log(\"algorithm\", \"GLR\")\n\nroot_run.log(\"rmse\", metrics[best_run_id][evaluator.getMetricName()])\n# Declare run completed\n\nroot_run.complete()\n\n#Download the model from the best run to a local folder\nbest_model_file_name = \"crime_prediction{0}.zip\".format(metrics[best_run_id][\"featureset\"])\nbest_run.download_file(name = 'outputs/' + model_name, output_file_path = best_model_file_name)\n##unzip the model to dbfs (as load() seems to require that) and load it.\nif os.path.isfile(model_dbfs) or os.path.isdir(model_dbfs):\n    shutil.rmtree(model_dbfs)\nshutil.unpack_archive(best_model_file_name, model_dbfs)\n\n#Register the model. THis is assuming that the model is downloaded from Azure ML service not from DBFS\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_dbfs, # this points to a local file\n                       model_name = model_name, # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"Crime Prediction using GLR {0}\".format(metrics[best_run_id][\"featureset\"]),\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description,  mymodel.version)\n"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### A short section for R users"],"metadata":{}},{"cell_type":"markdown","source":["####Approach using Sparklyr"],"metadata":{}},{"cell_type":"code","source":["%r\n# Installing latest version of Rcpp\ninstall.packages(\"Rcpp\")\n\n# Installing sparklyr takes a few minutes, becauses it installs +10 dependencies.\ninstall.packages(\"sparklyr\")\n\n# Load sparklyr package.\nlibrary(sparklyr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\">Installing package into ‘/databricks/spark/R/lib’\n(as ‘lib’ is unspecified)\ntrying URL 'https://cloud.r-project.org/src/contrib/Rcpp_1.0.1.tar.gz'\nContent type 'application/x-gzip' length 3661123 bytes (3.5 MB)\n==================================================\ndownloaded 3.5 MB\n\n* installing *source* package ‘Rcpp’ ...\n** package ‘Rcpp’ successfully unpacked and MD5 sums checked\n** libs\ng++  -I&quot;/usr/share/R/include&quot; -DNDEBUG -I../inst/include/     -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c Date.cpp -o Date.o\ng++  -I&quot;/usr/share/R/include&quot; -DNDEBUG -I../inst/include/     -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c Module.cpp -o Module.o\ng++  -I&quot;/usr/share/R/include&quot; -DNDEBUG -I../inst/include/     -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c Rcpp_init.cpp -o Rcpp_init.o\ng++  -I&quot;/usr/share/R/include&quot; -DNDEBUG -I../inst/include/     -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c api.cpp -o api.o\ng++  -I&quot;/usr/share/R/include&quot; -DNDEBUG -I../inst/include/     -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c attributes.cpp -o attributes.o\ng++  -I&quot;/usr/share/R/include&quot; -DNDEBUG -I../inst/include/     -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c barrier.cpp -o barrier.o\ng++ -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -Wl,-z,relro -o Rcpp.so Date.o Module.o Rcpp_init.o api.o attributes.o barrier.o -L/usr/lib/R/lib -lR\ninstalling to /databricks/spark/R/lib/Rcpp/libs\n** R\n** inst\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n** building package indices\n** installing vignettes\n** testing if installed package can be loaded\n* DONE (Rcpp)\n\nThe downloaded source packages are in\n\t‘/tmp/RtmpAfezER/downloaded_packages’\nInstalling package into ‘/databricks/spark/R/lib’\n(as ‘lib’ is unspecified)\ntrying URL 'https://cloud.r-project.org/src/contrib/sparklyr_1.0.0.tar.gz'\nContent type 'application/x-gzip' length 3570356 bytes (3.4 MB)\n==================================================\ndownloaded 3.4 MB\n\n* installing *source* package ‘sparklyr’ ...\n** package ‘sparklyr’ successfully unpacked and MD5 sums checked\n** R\n** inst\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n** building package indices\n** testing if installed package can be loaded\n* DONE (sparklyr)\n\nThe downloaded source packages are in\n\t‘/tmp/RtmpAfezER/downloaded_packages’\n</pre><pre style = 'font-size:10pt'></pre>"]}}],"execution_count":25},{"cell_type":"code","source":["%sql describe extended crime_dataset"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>crime_count</td><td>bigint</td><td>null</td></tr><tr><td>year</td><td>int</td><td>null</td></tr><tr><td>week</td><td>int</td><td>null</td></tr><tr><td>day</td><td>string</td><td>null</td></tr><tr><td>district</td><td>string</td><td>null</td></tr><tr><td>primary_type</td><td>string</td><td>null</td></tr><tr><td>school_test_performance</td><td>string</td><td>null</td></tr><tr><td>population</td><td>double</td><td>null</td></tr><tr><td>Unemployment_Rte</td><td>double</td><td>null</td></tr><tr><td>Median_Household_Income</td><td>double</td><td>null</td></tr><tr><td>Average_Commute_Time</td><td>double</td><td>null</td></tr><tr><td>Area</td><td>double</td><td>null</td></tr><tr><td>PRCP</td><td>double</td><td>null</td></tr><tr><td>SNOW</td><td>double</td><td>null</td></tr><tr><td>SNWD</td><td>double</td><td>null</td></tr><tr><td>TMAX</td><td>double</td><td>null</td></tr><tr><td>TMIN</td><td>double</td><td>null</td></tr><tr><td>TOBS</td><td>double</td><td>null</td></tr><tr><td>WT01</td><td>double</td><td>null</td></tr><tr><td>WT03</td><td>double</td><td>null</td></tr><tr><td>WT04</td><td>double</td><td>null</td></tr><tr><td>WT05</td><td>double</td><td>null</td></tr><tr><td>WT06</td><td>double</td><td>null</td></tr><tr><td>WT11</td><td>double</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>crime_dataset</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Created Time</td><td>Tue Apr 02 18:24:05 UTC 2019</td><td></td></tr><tr><td>Last Access</td><td>Thu Jan 01 00:00:00 UTC 1970</td><td></td></tr><tr><td>Created By</td><td>Spark 2.4.0</td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Location</td><td>dbfs:/user/hive/warehouse/crime_dataset</td><td></td></tr><tr><td>Serde Library</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td></td></tr><tr><td>InputFormat</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td></td></tr><tr><td>OutputFormat</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td></td></tr></tbody></table></div>"]}}],"execution_count":26},{"cell_type":"code","source":["%r\nlibrary(SparkR)\n# spark.conf\nlibrary(sparklyr)\nlibrary(dplyr)\n\nsc <- spark_connect(method = \"databricks\")\ncrime_tbl <-  sdf_sql(sc, \"select * from crime_dataset\")\nsdf_repartition(crime_tbl, partition_by = cbind('district'))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\"></pre><pre style = 'font-size:10pt'># Source: spark&lt;?&gt; [?? x 24]\n   crime_count  year  week day   district primary_type school_test_per…\n         &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;           \n 1           2  2018     3 Satu… 1.0      BATTERY      Below Average   \n 2           1  2018     4 Thur… 1.0      ASSAULT      Poor            \n 3           1  2018     5 Sund… 1.0      CRIMINAL DA… Excellent       \n 4           3  2003    23 Satu… 1.0      THEFT        Above Average   \n 5          19  2018    11 Frid… 1.0      THEFT        Poor            \n 6           2  2018    14 Frid… 1.0      ASSAULT      Poor            \n 7           1  2018    15 Mond… 1.0      OTHER OFFEN… Above Average   \n 8           4  2003    29 Sund… 1.0      THEFT        Below Average   \n 9           1  2017     9 Wedn… 1.0      OTHER OFFEN… Excellent       \n10           1  2017    11 Thur… 1.0      THEFT        Above Average   \n# … with more rows, and 17 more variables: population &lt;dbl&gt;,\n#   Unemployment_Rte &lt;dbl&gt;, Median_Household_Income &lt;dbl&gt;,\n#   Average_Commute_Time &lt;dbl&gt;, Area &lt;dbl&gt;, PRCP &lt;dbl&gt;, SNOW &lt;dbl&gt;, SNWD &lt;dbl&gt;,\n#   TMAX &lt;dbl&gt;, TMIN &lt;dbl&gt;, TOBS &lt;dbl&gt;, WT01 &lt;dbl&gt;, WT03 &lt;dbl&gt;, WT04 &lt;dbl&gt;,\n#   WT05 &lt;dbl&gt;, WT06 &lt;dbl&gt;, WT11 &lt;dbl&gt;</pre>"]}}],"execution_count":27},{"cell_type":"code","source":["%r\npartitions <- df %>%\n  sdf_partition(training = 0.7, test = 0.3, seed = 1111)\n\ndf_training <- partitions$training\ndf_test <- partitions$test\ndf <- crime_tbl %>%\n  filter(!is.na(district)) %>%\n  mutate(\n    district = paste0(\"d\", district)) %>%\n  select(crime_count , primary_type, school_test_performance, day,SNOW, population,Unemployment_Rte ) \n\n\ncrimes_pipeline <- ml_pipeline(sc) %>%\n  ft_dplyr_transformer(\n    tbl = df_training\n    ) %>%\n  ft_string_indexer(\n    input_col = \"day\",\n    output_col = \"day_idx\"  ) %>%\n  ft_string_indexer(\n    input_col = \"primary_type\",\n    output_col = \"primary_type_idx\"  ) %>%\n  ft_string_indexer(\n    input_col = \"school_test_performance\",\n    output_col = \"school_test_performance_idx\"  ) %>%\n#   ft_bucketizer(\n#     input.col = \"sched_dep_time\",\n#     output.col = \"hours\",\n#     splits = c(400, 800, 1200, 1600, 2000, 2400)\n#   )  %>%\n\n  ft_vector_assembler(\n    input_cols = cbind(\"day_idx\",\"primary_type_idx\",\"SNOW\", \"population\",\"Unemployment_Rte\")\n    ,output_col = \"features\",\n  )  %>%\n\n#   ft_r_formula(crime_count ~ features) %>% \n  ml_random_forest_classifier(features_col = \"features\",\n  label_col = \"school_test_performance_idx\",max_depth = 10)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\">Error : Unable to retrieve a Spark DataFrame from object of class function</pre>"]}}],"execution_count":28},{"cell_type":"code","source":["%r\ncrimes_pipeline <- ml_pipeline(sc) %>%\n  ft_dplyr_transformer(\n    tbl = df_training\n    ) %>%\n  ft_bucketizer(\n    input_col = \"crime_count\",\n    output_col = \"crime_level\",\n    splits = c(400, 800, 1200, 1600, 2000, 2400)\n  ) %>%\n  ft_vector_assembler(\n    input_cols = cbind(\"primary_type\",\"SNOW\", \"population\",\"Unemployment_Rte\")\n    ,output_col = \"features\",\n  )  %>%\n  ml_random_forest_classifier(formula = crime_level ~ school_test_performance+day +primary_type+SNOW+population+Unemployment_Rte,max_depth = 10)\n\n# model <- ml_random_forest_classifier(\n#   df,\n#   formula = school_test_performance ~ day +primary_type+SNOW+population+Unemployment_Rte\n# )\n# ml_tree_feature_importance(model)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\"></pre><pre style = 'font-size:10pt'></pre>"]}}],"execution_count":29},{"cell_type":"code","source":["%r\n\nfitted_pipeline <- ml_fit(\n  crimes_pipeline,\n  df_training\n)\n\n# \n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\">Error : java.lang.IllegalArgumentException: Data type string of column primary_type is not supported.\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:169)\n\tat org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:184)\n\tat org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:184)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:186)\n\tat org.apache.spark.ml.Pipeline.transformSchema(Pipeline.scala:184)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.Pipeline.fit(Pipeline.scala:136)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat sparklyr.Invoke.invoke(invoke.scala:139)\n\tat sparklyr.StreamHandler.handleMethodCall(stream.scala:123)\n\tat sparklyr.StreamHandler.read(stream.scala:66)\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:51)\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:4)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n\tat java.lang.Thread.run(Thread.java:748)\n\nIn addition: Warning messages:\n1: In do.call(.f, args, envir = .env) :\n  'what' must be a function or character string\n2: In do.call(.f, args, envir = .env) :\n  'what' must be a function or character string</pre>"]}}],"execution_count":30},{"cell_type":"code","source":["%r \n# install.packages(\"tidyverse\")\n# ml_tree_feature_importance(\n#   ml_stage(fitted_pipeline, 6)\n# )\n# ml_stage(model, 'decision_tree_classifier')$feature_importances\n\n# tibble(\n#   token = unlist(ml_stage(model, 'count_vectorizer')$vocabulary),\n#   importance = ml_stage(model, 'decision_tree_classifier')$feature_importances\n# )\n# ml_stage(fitted_pipeline,\"random_forest_classifier\")$feature_importances\n# ml_stage(fitted_pipeline,6)\n\nlibrary('tidyverse')\nfeature_cols <- \n  c(\"day\",\"primary_type\",\"SNOW\", \"population\",\"Unemployment_Rte\")\n\nmy_importance <- as.data.frame(cbind(feature_cols, ml_stage(fitted_pipeline, 6)$feature_importances))\ncolnames(my_importance) <- c('feature','importance')\nmy_importance  <- my_importance  %>% arrange(-as.numeric(importance))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\">Error : (list) object cannot be coerced to type 'double'\nIn addition: Warning message:\nIn do.call(.f, args, envir = .env) :\n  'what' must be a function or character string</pre>"]}}],"execution_count":31},{"cell_type":"code","source":["%r\nnext_ds <- crime_tbl %>% filter(primary_type == 'THEFT')\nnext_ds"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<pre style=\"font-size:10p\"></pre><pre style = 'font-size:10pt'># Source: spark<?> [?? x 24]\n   crime_count  year  week day   district primary_type school_test_per…\n         <dbl> <int> <int> <chr> <chr>    <chr>        <chr>           \n 1           3  2006    39 Wedn… 24.0     THEFT        Average         \n 2           1  2003    27 Wedn… 19.0     THEFT        Above Average   \n 3           3  2015    19 Frid… 17.0     THEFT        Below Average   \n 4           4  2013    33 Thur… 4.0      THEFT        Poor            \n 5           2  2014     9 Thur… 16.0     THEFT        Average         \n 6           5  2003    30 Mond… 11.0     THEFT        Below Average   \n 7           6  2001    26 Wedn… 7.0      THEFT        Below Average   \n 8           6  2002    15 Mond… 25.0     THEFT        Poor            \n 9           1  2007     3 Satu… 17.0     THEFT        Above Average   \n10           5  2007    44 Mond… 1.0      THEFT        Below Average   \n# … with more rows, and 17 more variables: population <dbl>,\n#   Unemployment_Rte <dbl>, Median_Household_Income <dbl>,\n#   Average_Commute_Time <dbl>, Area <dbl>, PRCP <dbl>, SNOW <dbl>, SNWD <dbl>,\n#   TMAX <dbl>, TMIN <dbl>, TOBS <dbl>, WT01 <dbl>, WT03 <dbl>, WT04 <dbl>,\n#   WT05 <dbl>, WT06 <dbl>, WT11 <dbl></pre>"]}}],"execution_count":32},{"cell_type":"markdown","source":["####Approach using SparkR"],"metadata":{}},{"cell_type":"code","source":["#Preparing data for a R model\nprocessing_pipeline = build_pipeline(['crime_count', 'year'])\nprocessing_model = processing_pipeline.fit(crime_df)\nrdata = processing_model.transform(crime_df)\nrdata.registerTempTable(\"rdata\")"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["%r\nlibrary(SparkR)\nrdf <- sql(\"select crime_count as label, features from rdata\")\ndf_list <- randomSplit(rdf, c(8.5,1.5), 2)\n\n\nmodelPath <- \"dbfs:/mnt/ml/rmodel\"\ntraining <- df_list[[1]]\ntest <- df_list[[2]]\n# # Fit a random forest regression model with spark.randomForest\nrandomForestModel <- spark.randomForest(training, label ~ features, \"regression\", numTrees = 10)\n\n# Model summary\nsummary(randomForestModel)\nwrite.ml(randomForestModel, modelPath)\n\n# Prediction\npredictions <- predict(model, test)\nhead(predictions)\n"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#Training with Random forest model\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nfrom pyspark.ml.regression import RandomForestRegressor\nimport os\nmodel_name = \"crime_prediction_RDF.mml\"\nmodel_dbfs = os.path.join(\"/dbfs\", model_name)\nrun_history_name = 'spark-ml-notebook'\n\nmyexperiment = Experiment(ws, \"AML_Crime_Prediction\")\nroot_run = myexperiment.start_logging()\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator(\n    labelCol=\"crime_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n\nregressor = RandomForestRegressor(featuresCol=\"features\", labelCol=\"crime_count\") \n\nparamGrid = ParamGridBuilder()\\\n  .addGrid(regressor.maxDepth, [10])\\\n  .addGrid(regressor.numTrees, [150])\\\n  .addGrid(regressor.maxBins , [55])\\\n  .build()\n\ncv = CrossValidator(estimator=regressor, evaluator=evaluator,estimatorParamMaps=paramGrid, numFolds=2)\n\nwith root_run.child_run(\"full columns\") as run:\n  run.log(\"featureset\", \"full\")\n\n\n\n  pipeline = build_pipeline(['crime_count', 'year'])\n\n  stages = pipeline.getStages()\n  stages = stages + [cv]\n  pipeline.setStages(stages)\n  print(pipeline.getStages())\n  pipelineModel = pipeline.fit(train)\n  predictions = pipelineModel.transform(test).cache()\n  print(\"Model  weather features: {} on  test set: {}\".format(evaluator.getMetricName(), evaluator.evaluate(predictions, {})))\n  run.log(evaluator.getMetricName(), evaluator.evaluate(predictions, {}))\n\n  pipelineModel.write().overwrite().save(model_name)\n\n  # upload the serialized model into run history record\n  mdl, ext = model_name.split(\".\")\n  model_zip = mdl + \".zip\"\n  shutil.make_archive(mdl, 'zip', model_dbfs)\n  run.upload_file(\"outputs/\" + model_name, model_zip)        \n\n  # now delete the serialized model from local folder since it is already uploaded to run history \n  shutil.rmtree(model_dbfs)\n  os.remove(model_zip)\n# with root_run.child_run(\"removed weather columns\") as run:\n  \n#   evaluator = RegressionEvaluator(\n#     labelCol=\"crime_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n#   regressor = RandomForestRegressor(featuresCol=\"features\", labelCol=\"crime_count\") \n\n#   paramGrid = ParamGridBuilder()\\\n#     .addGrid(regressor.maxDepth, [10])\\\n#     .addGrid(regressor.numTrees, [100])\\\n#     .addGrid(regressor.maxBins , [55])\\\n#     .build()\n\n#   run.log(\"featureset\", \"minus weather\")\n#   regressor = RandomForestRegressor(featuresCol=\"features\", labelCol=\"crime_count\") \n#   # dt = DecisionTreeRegressor(featuresCol=\"features\")\n\n\n\n\n#   cv = CrossValidator(estimator=regressor, evaluator=evaluator,estimatorParamMaps=paramGrid, numFolds=3)\n#   pipeline = build_pipeline(['crime_count', 'year','PRCP','SNOW','SNWD','TMAX','TMIN','TOBS','WT01','WT03','WT04','WT05','WT06','WT11'])\n#   stages = pipeline.getStages()\n#   stages = stages + [cv]\n#   pipeline.setStages(stages)\n#   pipelineModel = pipeline.fit(train)\n#   predictions = pipelineModel.transform(test).cache()\n#   print(\"Model without weather features: {} on  test set: {}\".format(evaluator.getMetricName(), evaluator.evaluate(predictions, {})))\n#   run.log(evaluator.getMetricName(), evaluator.evaluate(predictions, {}))\n\n#   pipelineModel.write().overwrite().save(model_name)\n\n#   # upload the serialized model into run history record\n#   mdl, ext = model_name.split(\".\")\n#   model_zip = mdl + \".zip\"\n#   shutil.make_archive(mdl, 'zip', model_dbfs)\n#   run.upload_file(\"outputs/\" + model_name, model_zip)        \n\n#   # now delete the serialized model from local folder since it is already uploaded to run history \n#   shutil.rmtree(model_dbfs)\n#   os.remove(model_zip)\n    \nroot_run_id = root_run.id\nprint (\"run id:\", root_run.id)\n\n#Load all run metrics from run history into a dictionary object.\nchild_runs = {}\n\nfor r in root_run.get_children():\n    child_runs[r.id] = r\n    \nmetrics = root_run.get_metrics(recursive=True)\nbest_run_id = min(metrics, key = lambda k: metrics[k][evaluator.getMetricName()])\nbest_run = child_runs[best_run_id]\nprint('Best run is:', best_run_id)\nprint('Metrics {0}: {1} by model {2}'.format(evaluator.getMetricName(), metrics[best_run_id][evaluator.getMetricName()],metrics[best_run_id][\"featureset\"]))\nroot_run.log(\"algorithm\", \"Randomforest\")\n\nroot_run.log(\"rmse\", metrics[best_run_id][evaluator.getMetricName()])\n# Declare run completed\n\nroot_run.complete()\n\n\n#Download the model from the best run to a local folder\nbest_model_file_name = \"crim_prediction{0}.zip\".format(metrics[best_run_id][\"featureset\"])\nbest_run.download_file(name = 'outputs/' + model_name, output_file_path = best_model_file_name)\n##unzip the model to dbfs (as load() seems to require that) and load it.\nif os.path.isfile(model_dbfs) or os.path.isdir(model_dbfs):\n    shutil.rmtree(model_dbfs)\nshutil.unpack_archive(best_model_file_name, model_dbfs)\n\n#Register the model. THis is assuming that the model is downloaded from Azure ML service not from DBFS\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_dbfs, # this points to a local file\n                       model_name = model_name, # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"Crime Prediction using Randomforest {0}\".format(metrics[best_run_id][\"featureset\"]),\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description,  mymodel.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[StringIndexer_24395bdbcba8, StringIndexer_cda44cc47655, StringIndexer_fc47cbf962bb, StringIndexer_32adf0b9b2a2, VectorAssembler_63900e4610fa, VectorIndexer_bed3e52d3431, CrossValidator_2d2bda11a6ad]\nModel  weather features: rmse on  test set: 1.7155604763164234\nrun id: 9aff0537-e7c3-4afb-b437-1bdecf785c97\nBest run is: a70d52a0-ea32-4558-aeb8-f2b76b80d5ee\nMetrics rmse: 1.7155604763164234 by model full\nRegistering model crime_prediction_RDF.mml\ncrime_prediction_RDF.mml Crime Prediction using Randomforest full 5\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["## Approach 2: Training using traditional SK Learn"],"metadata":{}},{"cell_type":"markdown","source":["In many cases Spark MLib though scalable does not meet your needs. In General, SK Learn offers you much more option to fine tune models and has more algorithms to support your needs. Also, you may want train model using a deep learning library that Spark ML is not idea for the task. Below is model training using SKLearn and Azure ML can always be used to track metrics and manage your models"],"metadata":{}},{"cell_type":"code","source":["# loading data from the stored table, limit 100k out of 8 m records as training in single node with SK learn will be slow\ncrime_df = spark.sql(\"select * from crime_dataset limit 100000\").na.drop()\ndisplay(crime_df)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler\nfrom sklearn.externals import joblib\nfrom sklearn import metrics as metr\nimport numpy as np\nimport os\nfrom  sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n#directory to save preprocessing and prediction models\nsavedir ='/dbfs/ml'\nmodel_name = 'ml.joblib'\nmodel_dbfs = os.path.join(\"/dbfs\", model_name)\n\nft_name = 'ft.joblib'\n# dbutils.fs.rm(savedir, True)\n# dbutils.fs.mkdirs(savedir)\n\nft_destination = os.path.join(savedir, ft_name)\nml_destination = os.path.join(savedir, model_name)\npdCrime = crime_df.toPandas()\nfeatures_df = pdCrime.drop(['crime_count','year'], axis=1)\ny = pdCrime.pop('crime_count')\nft= ColumnTransformer(transformers = [(\"ohe\",OneHotEncoder(handle_unknown='ignore'),['day','primary_type','school_test_performance', 'district'])],remainder =StandardScaler())\n#transform \nft.fit(features_df)\nif not os.path.isdir(savedir):\n  os.mkdir(savedir)\n#save the feature transformation model\njoblib.dump(value =ft,filename=ft_destination)\nX = ft.transform(features_df)\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\nprint(\"We have {} training examples and {} test examples.\".format(X_train.size, Y_train.size))\nroot_run = myexperiment.start_logging()\n\n#build randomforest regressor\nwith root_run.child_run(\"randomforest\") as run:\n  run.log(\"algorithm\", \"SKLearn_Randomforest\")\n  randomforestregressor = RandomForestRegressor(max_depth=2, random_state=0,  n_estimators=10)\n\n  param_grid = {\n      \"max_depth\": [6],\n        \"n_estimators\": [100]\n\n  }\n\n  regression_model = GridSearchCV(randomforestregressor, param_grid, cv=3)\n\n\n\n\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n  regression_model.fit(X_train, y_train)\n  y_pred = regression_model.predict(X_test)\n\n  mae = metr.mean_absolute_error(y_test, y_pred)\n  mse = metr.mean_squared_error(y_test, y_pred)\n  rmse = np.sqrt(mse)\n\n\n  print('mae %f\\t mse %f\\t rmse %f'% (mae, mse, rmse))\n  run.log(\"rmse\", rmse)\n\n  joblib.dump(regression_model.best_estimator_,ml_destination)\n\n  mdl, ext = model_name.split(\".\")\n  model_zip = mdl + \".zip\"\n  shutil.make_archive(mdl, 'zip', savedir)\n  run.upload_file(\"outputs/\" + model_zip, model_zip)        \n\n  # now delete the serialized model from local folder since it is already uploaded to run history \n  os.remove(model_zip)\n  \nwith root_run.child_run(\"ElasticNet\") as run:\n  run.log(\"algorithm\", \"SKLearn_ElasticNet\")\n  elasregressor = ElasticNet()\n\n  param_grid = {\n      \"alpha\": [ 1.0,2.0],\n\n  }\n\n  regression_model = GridSearchCV(elasregressor, param_grid, cv=3)\n\n\n\n\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n  regression_model.fit(X_train, y_train)\n  y_pred = regression_model.predict(X_test)\n\n  mae = metr.mean_absolute_error(y_test, y_pred)\n  mse = metr.mean_squared_error(y_test, y_pred)\n  rmse = np.sqrt(mse)\n\n\n  print('mae %f\\t mse %f\\t rmse %f'% (mae, mse, rmse))\n  run.log(\"rmse\", rmse)\n\n\n  joblib.dump(regression_model.best_estimator_,ml_destination)\n\n  mdl, ext = model_name.split(\".\")\n  model_zip = mdl + \".zip\"\n  shutil.make_archive(mdl, 'zip', savedir)\n  run.upload_file(\"outputs/\" + model_zip, model_zip)        \n\n  # now delete the serialized model from local folder since it is already uploaded to run history \n  os.remove(model_zip)\n  \nroot_run_id = root_run.id\nprint (\"run id:\", root_run.id)\n\n#Load all run metrics from run history into a dictionary object.\nchild_runs = {}\n\nfor r in root_run.get_children():\n    child_runs[r.id] = r\n\nmetrics = root_run.get_metrics(recursive=True)\nbest_run_id = min(metrics, key = lambda k: metrics[k][\"rmse\"])\nbest_run = child_runs[best_run_id]\nprint('Best run is:', best_run_id)\nprint('Metrics {0}: {1} by model {2}'.format(\"rmse\", metrics[best_run_id][\"rmse\"],metrics[best_run_id][\"algorithm\"]))\nroot_run.log(\"algorithm\", metrics[best_run_id][\"algorithm\"])\n\nroot_run.log(\"rmse\", metrics[best_run_id][\"rmse\"])\n# Declare run completed\nroot_run.complete()\n\n\n#Download the model from the best run to a local folder\nbest_model_file_name = \"crime_prediction{0}.zip\".format(metrics[best_run_id][\"algorithm\"])\nbest_run.download_file(name = 'outputs/' + model_zip, output_file_path = best_model_file_name)\n##unzip the model to dbfs (as load() seems to require that) and load it.\nif os.path.isfile(model_dbfs) or os.path.isdir(model_dbfs):\n    shutil.rmtree(model_dbfs)\nshutil.unpack_archive(best_model_file_name, model_dbfs)\n\n\n#Register the model. THis is assuming that the model is downloaded from Azure ML service not from DBFS\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_dbfs, # this points to a local file\n                       model_name = model_name, # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"Crime Prediction using  {0}\".format(metrics[best_run_id][\"algorithm\"]),\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description,  mymodel.version)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["##Creating any custom report from Azure ML Runs"],"metadata":{}},{"cell_type":"code","source":["rmse_list =[]\nruns =myexperiment.get_runs(include_children=True)\nfor run in runs:\n  metrics = run.get_metrics()\n\n  rmse = metrics.get(\"rmse\", 999.0)\n  if rmse != 999.0:\n    metrics = run.get_metrics()\n    run_id = run.id\n    experiement =run.experiment.name\n    algorithm = metrics.get(\"algorithm\", \"None\")\n    row = {\"algorithm\":algorithm, \"rmse\": rmse, \"run_id\":run_id, \"experiment\":experiement}\n    rmse_list.append(row)\nprint(rmse_list)\ndisplay(spark.createDataFrame(rmse_list))"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"06 - MLlib Classification Training","notebookId":3955808116160634},"nbformat":4,"nbformat_minor":0}
